{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vagenas/llama_index/blob/add-docling-reader/docs/docs/examples/data_connectors/DoclingPDFReaderDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!-- TODO update link -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling PDF Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docling](https://github.com/DS4SD/docling) extracts PDF content into a rich representation (incl. layout, tables etc.) which it can export to Markdown or JSON.\n",
    "\n",
    "The `DoclingPDFReader` seamlessly integrates Docling into LlamaIndex, enabling you to:\n",
    "- use PDF files in your LLM applications with ease and speed, and\n",
    "- leverage Docling's rich format for advanced, document-native grounding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "filterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\")\n",
    "filterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\")\n",
    "# https://github.com/huggingface/transformers/issues/5486:\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Markdown export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a simple RAG pipeline, we:\n",
    "- define a `DoclingPDFReader`, which by default exports to Markdown, and\n",
    "- use a standard node parser for these Markdown-based docs, e.g. a `MarkdownNodeParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ac9cbbda5544d59a95f436f4187eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.readers.docling import DoclingPDFReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "\n",
    "reader = DoclingPDFReader()\n",
    "node_parser = MarkdownNodeParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the relevant parameters as well as a couple useful helper functions for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.core.readers.base import BaseReader\n",
    "from llama_index.core.node_parser import NodeParser\n",
    "from llama_index.core.base.response.schema import RESPONSE_TYPE\n",
    "from tempfile import mkdtemp\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_env_var(key, default=None):\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        try:\n",
    "            return userdata.get(key)\n",
    "        except userdata.SecretNotFoundError:\n",
    "            pass\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return os.environ.get(key, default)\n",
    "\n",
    "\n",
    "HF_TOKEN = get_env_var(\"HF_TOKEN\")  # optional env var, for higher quota\n",
    "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")  # temp path for this example\n",
    "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"  # Docling Technical Report\n",
    "QUERY = \"Which are the main AI models in Docling?\"\n",
    "EMBED_MODEL = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "GEN_MODEL = HuggingFaceInferenceAPI(\n",
    "    token=HF_TOKEN,\n",
    "    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    ")\n",
    "\n",
    "\n",
    "def ingest(reader: BaseReader, node_parser: NodeParser) -> VectorStoreIndex:\n",
    "    vector_store = MilvusVectorStore(\n",
    "        uri=MILVUS_URI,\n",
    "        dim=len(EMBED_MODEL.get_text_embedding(\"hi\")),\n",
    "        overwrite=True,\n",
    "    )\n",
    "    docs = reader.load_data(file_path=FILE_PATH)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents=docs)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex(\n",
    "        nodes=nodes,\n",
    "        embed_model=EMBED_MODEL,\n",
    "        storage_context=storage_context,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    return index\n",
    "\n",
    "\n",
    "def print_qa(query_res: RESPONSE_TYPE):\n",
    "    print(f\"Question:\\n{QUERY}\\n\\nAnswer:\\n{query_res.response.strip()}\")\n",
    "    for i, res in enumerate(query_res.source_nodes):\n",
    "        print()\n",
    "        print(f\"Source {i+1}:\")\n",
    "        print(f\"  text: {repr(res.text.strip())}\")\n",
    "        for key in res.metadata:\n",
    "            print(f\"  {key}: {res.metadata.get(key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all pieces in place, we are now ready to ingest into the vector store and ask questions on our document content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa66b3eb2984070af02bd1b55f6e564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the main AI models in Docling?\n",
      "\n",
      "Answer:\n",
      "The main AI models in Docling are a layout analysis model, which is an accurate object-detector for page elements, and TableFormer, a state-of-the-art table structure recognition model.\n",
      "\n",
      "Source 1:\n",
      "  text: '3.2 AI models\\n\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.'\n",
      "  dl_doc_hash: 556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa\n",
      "  Header_2: 3.2 AI models\n",
      "\n",
      "Source 2:\n",
      "  text: \"5 Applications\\n\\nThanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed enterprise document search, passage retrieval or classification use-cases, or support knowledge extraction pipelines, allowing specific treatment of different structures in the document, such as tables, figures, section structure or references. For popular generative AI application patterns, such as retrieval-augmented generation (RAG), we provide quackling , an open-source package which capitalizes on Docling's feature-rich document output to enable document-native optimized vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIndex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build document-derived datasets. With its powerful table structure recognition, it provides significant benefit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal training datasets.\"\n",
      "  dl_doc_hash: 556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa\n",
      "  Header_2: 5 Applications\n"
     ]
    }
   ],
   "source": [
    "index = ingest(reader=reader, node_parser=node_parser)\n",
    "query_res = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\n",
    "print_qa(query_res=query_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using native Docling format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To leverage Docling's rich native format, we:\n",
    "- create a `DoclingPDFReader` with `export_type=\"json\"`, and\n",
    "- employ a `DoclingNodeParser` in order to appropriately parse that native Docling format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e855c742aaa483e9d5b43f39c4c3355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.node_parser.docling import DoclingNodeParser\n",
    "\n",
    "reader = DoclingPDFReader(export_type=\"json\")\n",
    "node_parser = DoclingNodeParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the pipeline with this setup. Notice how, besides the response itself, we now also get document-native grounding, incl. page number and bounding box information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66dfede245c441c8fe826f5bdf808cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the main AI models in Docling?\n",
      "\n",
      "Answer:\n",
      "The main AI models in Docling are a layout analysis model, which is an accurate object-detector for page elements, and TableFormer, a state-of-the-art table structure recognition model.\n",
      "\n",
      "Source 1:\n",
      "  text: 'As part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure recognition model. We provide the pre-trained weights (hosted on huggingface) and a separate package for the inference code as docling-ibm-models . Both models are also powering the open-access deepsearch-experience, our cloud-native service for knowledge exploration tasks.'\n",
      "  dl_doc_hash: 556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa\n",
      "  path: #/main-text/36\n",
      "  heading: 3.2 AI models\n",
      "  page: 3\n",
      "  bbox: [107.25257873535156, 330.1919250488281, 504.05230712890625, 406.1560974121094]\n",
      "\n",
      "Source 2:\n",
      "  text: 'With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.'\n",
      "  dl_doc_hash: 556ad9e23b6d2245e36b3208758cf0c8a709382bb4c859eacfe8e73b14e635aa\n",
      "  path: #/main-text/10\n",
      "  heading: 1 Introduction\n",
      "  page: 1\n",
      "  bbox: [107.16082763671875, 83.33924865722656, 504.09375, 136.9646759033203]\n"
     ]
    }
   ],
   "source": [
    "index = ingest(reader=reader, node_parser=node_parser)\n",
    "query_res = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\n",
    "print_qa(query_res=query_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
